
%%%
% Discuss how neighboring weights were applied and what the results were
% TODO: results
%%%

\subsubsection*{Neighboring Weights}
\label{sec:findings-expts-neighbors}

%%%
% Process
%%%

%%%
In order to smooth out the strategy graphs
and prevent isolated states of separate weights,
a blending of neighboring weights was developed.
%
Rather than simply take the set of weights allocated to a single score location,
the agent instead takes a weighted average of all surrounding weight vectors
with its own location.
%
In other words,
\[
    \wvecm'_{p,o,d} = %\mathrm{l1norm}\left(
    \left|
    X\wvecm_{p,o,d} +
    Y \sum_{i\in\{-1,0,1\}} \sum_{j\in\{-1,0,1\}} w_{m+i,o+j,d}
    \right|_1
    %\right)
\]
where $X$, $Y$ are ratios of each vector's effect, $X+Y = 1$,
and $m+i$, $o+j \in [0,120]$.
%
The desired effect was to allow a score location to learn from its neighbors
so that a neighborhood effect was present in the decision.
%%%


\paragraph*{Results}

%%%
% Results:
%	Mostly same appearnace
%	fewer islands in hand_max_min territory for cribminavg/peggingminavggiven/
%		peggingmaxmedgained/peggingmaxavggained
%	Losing territory still in limbo, not much certainty there.
%%%

%%%
% Not really good at making a blending/gradient
% Definitely did eliminate islands though
%%%

\input{sections/findings/experiments/neighbors/strats.fig.tex}

%%%
The agent was not capable of weighting the different strategies in a
gradient-like manner
by using the neighboring score locations' weights vectors.
%
In fact,
the \handmaxavg\ strategy,
which one would expect most to form a gradient with and around the
\handmaxmin\ strategy,
was perhaps the most negatively affected.
%
As seen in Figure~\ref{fig:neighbor-strats},
the \handmaxavg\ strategy graph has become more sparse in the winning
states (lower left)
with very little gray area surrounding the black.
%%%

%%%
Interestingly,
while the neighboring weights did not solidify any presence in the graphs,
the new training method did make progress in negative space.
%
This is to say that
the weighted neighbors learning method eliminated the usually present islands
of a single strategy within a swathe of another dominant strategy.
%
This white-space was present in both the winning and losing states.
%
This finding leads to the conclusion that weighted learning techniques
do indeed allow for a sharing of knowledge between like states,
but only insofar as to know what not to do.
%%%

%%%
Furthermore,
there is still a vast degree of uncertainty present in the losing states of
the strategy graphs.
%
The theory that the certainty of the winning states might potentially
bleed over into the losing side was not demonstrated over the course of
the first half million training games.
%
However,
since the elimination of islands shows an improvement in
preventing lucky happenstance to dictate a space's future,
the neighboring weights training method has shown usefulness in training a
cribbage agent in which states neighboring states are often similar in nature.
%%%

