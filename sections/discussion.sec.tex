\section{Discussion}
\label{sec:disc}


%%%
% Discussion
%%%

%%%
This thesis focused on an attempt to use
$\epsilon$-greedy Monte Carlo methods with exploring starts
to develop a well-playing
cribbage agent capable of weighing different strategies
with the intention of using these learned weights to 
potentially
improve the play of the author and readers.
%
In the primary objective of evolving a cribbage agent to a good strategy,
despite the setbacks of poor performance on a per-game level,
the agent did remarkably well
by removing irrelevant strategies
such as \handmaxmed\ and \peggingmaxmedgained\ 
and emphasizing more useful strategies
like \handmaxavg\ and \handmaxmin.
%%%

%%%
This section will describe some reasons for successes and failures of the learning
process as well as potential future applications or improvements to the
system which can help make a successful cribbage-playing agent in the future.
%%%

\input{sections/discussion/future.sub.sec.tex}

%\input{sections/discussion/value.sub.sec.tex}

\input{sections/discussion/shortcomings.sub.sec.tex}

\input{sections/discussion/usefulness.sub.sec.tex}

