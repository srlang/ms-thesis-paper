%%%
% How the results given can be of use to a future project
% despite shortcomings
%%%

\subsection{Usefulness of Results}
\label{sec:disc-usefulness}

%%%
% Intro paragraph*
%%%

%%%
Despite the final learned agent's shortcomings in ability to consistently win
a single game,
the deliverables of this project can still be applied to expand the current
knowledge of cribbage as well as serve as a guidance story.
%
As they were intended from the outset,
the generated strategy graphs can serve as a set of guidelines as to how a
player ``should'' be playing a certain hand.
%
Although a human player may not be able to calculate the statistics which the
agent used as accurately as a computer,
a fair amount of experience and intuition can be gained through repeated
play which should approximate the expected and guaranteed returns well.
%%%

%%%
The agent's successes in the macro scale can also be of use to those
applications which also operate on the scale of thousands to millions of games.
%
Mainly,
the developed agent could be used for a first round or two of training
of a value-function based agent.
%
Rather than learning from the self-play with no existing knowledge,
a policy-following agent can be played against instead.
%
Playing an agent of greater difficulty would allow the value function optimizing
agent to more quickly converge to an optimum.
%
Since the results of this thesis were achieved without imparting much particular 
pre-existing domain knowledge to the initial policy,
this faster convergence to optimal would not be unfairly biased
towards any form of human play,
thus lowering training time without introducing many suboptimalities.
%%%





%\input{sections/discussion/usefulness/*}
