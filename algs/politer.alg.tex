% Policy iteration algorithm

\begin{algorithm}
\caption{Policy Iteration}
\label{alg:politer}

\begin{enumerate}[topsep=0pt]

	\item Initialization: \\
		$V(s) \in \Reals$
		and
		$\policy(s) \in \Actions(s)$ arbitrarily for all $s$

	\item Policy Evaluation (see Algorithm~\ref{alg:poleval}).


	\item Policy Improvement:
		\begin{algorithmic}[1]
			\State $\textit{policy-stable} \gets \textit{true}$

			\ForAll{$s \in \States$}

				\State $\textit{old-action} \gets \policy(s)$

				\State $\policy(s) \gets
					\argmax_{a} \sum_{s',r} {
						p(s',r|s,a)\left[r+\gamma V(s')\right]
						}$

				\If {$\textit{old-action} \neq \policy(s)$}
					\State $\textit{policy-stable} \gets \textit{false}$
				\EndIf

			\EndFor

			\If {\textit{policy-stable}}
				\State \Return $V \approx v_*$
					and $\policy \approx \policy_*$
			\Else
				\State Go to Step 2.
			\EndIf
		\end{algorithmic}

\end{enumerate}

\end{algorithm}
